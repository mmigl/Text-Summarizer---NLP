{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mehak\\\\OneDrive\\\\NLP_Project\\\\Text-Summarizer---NLP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True) \n",
    "class ModelTrainerConfig:  \n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model: Path\n",
    "    num_train_epochs: int\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    per_device_eval_batch_size: int\n",
    "    weight_decay: float\n",
    "    logging_steps: int\n",
    "    evaluation_strategy: str\n",
    "    eval_steps: int\n",
    "    save_steps: float\n",
    "    gradient_accumulation_steps: int\n",
    "    learning_rate: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir =  config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model = config.model,\n",
    "            num_train_epochs = params.num_train_epochs,\n",
    "            warmup_steps = params.warmup_steps,\n",
    "            per_device_train_batch_size = params.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size = params.per_device_eval_batch_size,\n",
    "            weight_decay = params.weight_decay,\n",
    "            logging_steps = params.logging_steps,\n",
    "            evaluation_strategy = params.evaluation_strategy,\n",
    "            eval_steps = params.eval_steps,\n",
    "            save_steps = params.save_steps,\n",
    "            gradient_accumulation_steps = params.gradient_accumulation_steps,\n",
    "            learning_rate = params.learning_rate\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehak\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-04 11:05:12,492: INFO: config: PyTorch version 2.4.1 available.]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model)\n",
    "\n",
    "        for param in model_pegasus.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in model_pegasus.model.encoder.layers[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in model_pegasus.model.decoder.layers[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        dataset = load_from_disk(self.config.data_path)\n",
    "        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n",
    "\n",
    "        trainer_args = TrainingArguments(\n",
    "            output_dir=self.config.root_dir, num_train_epochs=self.config.num_train_epochs, warmup_steps=self.config.warmup_steps,\n",
    "            per_device_train_batch_size=self.config.per_device_train_batch_size, per_device_eval_batch_size=self.config.per_device_eval_batch_size,\n",
    "            weight_decay=self.config.weight_decay, logging_steps=self.config.logging_steps,\n",
    "            evaluation_strategy=self.config.evaluation_strategy, eval_steps=self.config.eval_steps, save_steps=1e6,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps, learning_rate=5e-5\n",
    "            ) \n",
    "\n",
    "        optimizer = AdamW([\n",
    "            {\"params\": model_pegasus.model.encoder.layers[-2:].parameters(), \"lr\": 3e-5},\n",
    "            {\"params\": model_pegasus.model.decoder.layers[-2:].parameters(), \"lr\": 3e-5},\n",
    "        ], lr=5e-5, weight_decay=self.config.weight_decay)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model_pegasus,\n",
    "            args=trainer_args,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=seq2seq_data_collator,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            optimizers=(optimizer, None)\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # Save the fine-tuned model\n",
    "        model_pegasus.save_pretrained(os.path.join(self.config.root_dir, \"pegasus-samsum-model\"))\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir, \"tokenizer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-04 11:05:32,279: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-02-04 11:05:32,290: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-02-04 11:05:32,296: INFO: common: created directory at: artifacts]\n",
      "[2025-02-04 11:05:32,299: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\mehak\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\mehak\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehak\\AppData\\Local\\Temp\\ipykernel_29668\\2742270778.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  1%|‚ñè         | 10/690 [27:49<25:56:20, 137.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1692, 'grad_norm': 54.798912048339844, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 20/690 [44:10<22:40:37, 121.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0284, 'grad_norm': 45.83332824707031, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 30/690 [1:06:10<35:43:06, 194.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1191, 'grad_norm': 46.864227294921875, 'learning_rate': 1.8e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 40/690 [1:39:28<35:54:49, 198.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.023, 'grad_norm': 51.96515655517578, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 50/690 [2:08:39<30:14:33, 170.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0195, 'grad_norm': 49.2462043762207, 'learning_rate': 3e-06, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñä         | 60/690 [3:26:01<31:53:23, 182.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0041, 'grad_norm': 45.92800521850586, 'learning_rate': 3.6e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 70/690 [3:37:53<13:12:44, 76.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9773, 'grad_norm': 44.335018157958984, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 80/690 [4:01:32<24:44:36, 146.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9305, 'grad_norm': 44.184329986572266, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 90/690 [4:28:19<26:42:59, 160.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9664, 'grad_norm': 40.07671356201172, 'learning_rate': 5.4e-06, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 100/690 [4:45:57<17:11:22, 104.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9985, 'grad_norm': 45.71270751953125, 'learning_rate': 6e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 110/690 [5:07:28<24:01:41, 149.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0005, 'grad_norm': 39.997108459472656, 'learning_rate': 6.6e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 120/690 [5:24:54<15:16:29, 96.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9654, 'grad_norm': 42.51305389404297, 'learning_rate': 7.2e-06, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 130/690 [5:50:31<24:32:12, 157.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9162, 'grad_norm': 45.5532112121582, 'learning_rate': 7.8e-06, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 140/690 [6:17:15<25:13:47, 165.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0022, 'grad_norm': 32.12028884887695, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 150/690 [6:42:29<17:03:10, 113.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8539, 'grad_norm': 32.148197174072266, 'learning_rate': 9e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 160/690 [6:57:30<13:01:56, 88.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8208, 'grad_norm': 30.895307540893555, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñç       | 170/690 [7:13:10<14:09:34, 98.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7471, 'grad_norm': 36.40605926513672, 'learning_rate': 1.02e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 180/690 [7:28:13<13:30:59, 95.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8072, 'grad_norm': 36.155181884765625, 'learning_rate': 1.08e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 190/690 [7:42:29<11:59:27, 86.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6513, 'grad_norm': 30.261356353759766, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñâ       | 200/690 [7:56:58<12:02:30, 88.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6736, 'grad_norm': 40.970069885253906, 'learning_rate': 1.2e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 210/690 [8:11:39<11:58:16, 89.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6263, 'grad_norm': 28.737869262695312, 'learning_rate': 1.26e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 220/690 [8:26:21<11:52:05, 90.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5887, 'grad_norm': 27.367626190185547, 'learning_rate': 1.32e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 230/690 [8:50:09<11:42:36, 91.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5395, 'grad_norm': 24.992799758911133, 'learning_rate': 1.3800000000000002e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 240/690 [9:01:40<8:55:16, 71.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5209, 'grad_norm': 33.42159652709961, 'learning_rate': 1.44e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 250/690 [9:13:00<8:39:20, 70.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4914, 'grad_norm': 23.269376754760742, 'learning_rate': 1.5e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 260/690 [9:25:00<8:22:35, 70.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5324, 'grad_norm': 26.336008071899414, 'learning_rate': 1.56e-05, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 270/690 [9:37:42<9:32:27, 81.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4852, 'grad_norm': 24.361303329467773, 'learning_rate': 1.62e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 280/690 [9:52:50<10:01:27, 88.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4527, 'grad_norm': 30.39527702331543, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 290/690 [10:08:01<10:22:45, 93.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4027, 'grad_norm': 19.92495346069336, 'learning_rate': 1.74e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 300/690 [10:22:01<8:46:07, 80.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5025, 'grad_norm': 19.067960739135742, 'learning_rate': 1.8e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 310/690 [10:37:00<9:30:49, 90.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3615, 'grad_norm': 18.748706817626953, 'learning_rate': 1.86e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 320/690 [11:45:38<24:16:43, 236.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3629, 'grad_norm': 21.79363441467285, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 330/690 [11:56:45<6:57:01, 69.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3715, 'grad_norm': 19.677841186523438, 'learning_rate': 1.98e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 340/690 [12:08:19<6:51:39, 70.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.288, 'grad_norm': 25.769872665405273, 'learning_rate': 2.04e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 350/690 [12:19:42<6:44:48, 71.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3007, 'grad_norm': 18.25079345703125, 'learning_rate': 2.1e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 360/690 [12:32:26<6:39:03, 72.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2821, 'grad_norm': 20.840227127075195, 'learning_rate': 2.16e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 370/690 [12:44:06<6:00:37, 67.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2682, 'grad_norm': 122.87893676757812, 'learning_rate': 2.22e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 380/690 [12:55:03<5:40:24, 65.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2433, 'grad_norm': 19.380781173706055, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 390/690 [13:05:36<5:12:33, 62.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.325, 'grad_norm': 35.104103088378906, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 400/690 [13:16:03<5:03:26, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2856, 'grad_norm': 27.29322624206543, 'learning_rate': 2.4e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 410/690 [13:26:53<4:55:01, 63.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2438, 'grad_norm': 15.272923469543457, 'learning_rate': 2.4599999999999998e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 420/690 [13:37:54<5:01:25, 66.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1757, 'grad_norm': 13.432772636413574, 'learning_rate': 2.52e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 430/690 [13:48:41<4:29:26, 62.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1508, 'grad_norm': 19.99643325805664, 'learning_rate': 2.58e-05, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 440/690 [13:59:28<4:36:04, 66.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1506, 'grad_norm': 14.815589904785156, 'learning_rate': 2.64e-05, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 450/690 [14:09:56<4:09:29, 62.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1381, 'grad_norm': 17.810791015625, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 460/690 [14:19:38<3:44:06, 58.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1008, 'grad_norm': 13.77190113067627, 'learning_rate': 2.7600000000000003e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 470/690 [14:29:57<3:29:17, 57.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1548, 'grad_norm': 17.559022903442383, 'learning_rate': 2.8199999999999998e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 480/690 [14:40:21<3:43:58, 63.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1155, 'grad_norm': 14.225872039794922, 'learning_rate': 2.88e-05, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 490/690 [14:51:11<3:32:26, 63.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1069, 'grad_norm': 16.647958755493164, 'learning_rate': 2.94e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 500/690 [15:01:58<3:29:10, 66.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1241, 'grad_norm': 17.302061080932617, 'learning_rate': 3e-05, 'epoch': 2.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 500/690 [15:10:10<3:29:10, 66.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7819159030914307, 'eval_runtime': 492.5138, 'eval_samples_per_second': 1.661, 'eval_steps_per_second': 0.416, 'epoch': 2.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 510/690 [15:20:50<3:31:40, 70.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1251, 'grad_norm': 17.829133987426758, 'learning_rate': 2.8421052631578946e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 520/690 [15:31:15<2:55:26, 61.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.087, 'grad_norm': 17.286632537841797, 'learning_rate': 2.6842105263157896e-05, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 530/690 [15:41:27<2:52:01, 64.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0961, 'grad_norm': 14.258685111999512, 'learning_rate': 2.526315789473684e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 540/690 [15:52:07<2:30:08, 60.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0998, 'grad_norm': 14.123178482055664, 'learning_rate': 2.368421052631579e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 550/690 [16:03:04<2:27:07, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0891, 'grad_norm': 18.787899017333984, 'learning_rate': 2.2105263157894736e-05, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 560/690 [16:12:47<2:08:49, 59.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9568, 'grad_norm': 12.423715591430664, 'learning_rate': 2.0526315789473685e-05, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 570/690 [16:23:53<2:09:27, 64.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0526, 'grad_norm': 24.086139678955078, 'learning_rate': 1.894736842105263e-05, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 580/690 [16:35:08<2:02:47, 66.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0476, 'grad_norm': 22.288957595825195, 'learning_rate': 1.736842105263158e-05, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 590/690 [16:44:53<1:40:35, 60.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9993, 'grad_norm': 15.788033485412598, 'learning_rate': 1.5789473684210526e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 600/690 [16:55:36<1:35:08, 63.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1155, 'grad_norm': 15.590600967407227, 'learning_rate': 1.4210526315789473e-05, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 610/690 [17:06:42<1:26:25, 64.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0441, 'grad_norm': 12.765673637390137, 'learning_rate': 1.263157894736842e-05, 'epoch': 2.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 620/690 [17:17:39<1:17:19, 66.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9814, 'grad_norm': 13.159260749816895, 'learning_rate': 1.1052631578947368e-05, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 630/690 [17:28:18<1:06:22, 66.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0933, 'grad_norm': 16.337514877319336, 'learning_rate': 9.473684210526315e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 640/690 [17:38:41<51:13, 61.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0434, 'grad_norm': 12.050564765930176, 'learning_rate': 7.894736842105263e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 650/690 [17:49:40<42:13, 63.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0485, 'grad_norm': 13.533679962158203, 'learning_rate': 6.31578947368421e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 660/690 [18:00:09<30:30, 61.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0756, 'grad_norm': 43.373294830322266, 'learning_rate': 4.736842105263158e-06, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 670/690 [18:10:51<21:33, 64.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0593, 'grad_norm': 44.632659912109375, 'learning_rate': 3.157894736842105e-06, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 680/690 [18:21:56<10:50, 65.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9913, 'grad_norm': 13.256025314331055, 'learning_rate': 1.5789473684210526e-06, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [18:32:20<00:00, 63.01s/it]c:\\Users\\mehak\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9793, 'grad_norm': 14.96561336517334, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [18:32:25<00:00, 96.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 66745.8018, 'train_samples_per_second': 0.662, 'train_steps_per_second': 0.01, 'train_loss': 2.425387382507324, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
